{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "175e2d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Necessary libraries\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7abc6f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation function and there derivative\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x*(1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfeb34d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean squared error(mse)\n",
    "def mean_squarred_error(y_true,y_pred):\n",
    "    return np.mean(np.square(y_true-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8eb7bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Neural Network Class\n",
    "class BasicNeuralNetwork:\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        self.weights_input_hidden=np.random.randn(input_size,hidden_size)\n",
    "        self.weights_hidden_output=np.random.randn(hidden_size,output_size)\n",
    "        self.bias_hidden=np.random.randn(1,hidden_size)\n",
    "        self.bias_output=np.random.randn(1,output_size)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self,X):\n",
    "        self.hidden_input=np.dot(X,self.weights_input_hidden)+self.bias_hidden\n",
    "        self.hidden_output=sigmoid(self.hidden_input)\n",
    "        self.output_input=np.dot(self.hidden_output,self.weights_hidden_output)+self.bias_output\n",
    "        self.output=sigmoid(self.output_input)\n",
    "        return self.output\n",
    "\n",
    "    # backward pass and weights update\n",
    "    def backward(self,X,y,output,learning_rate):\n",
    "        output_error=y-output\n",
    "        output_delta=output_error*sigmoid_derivative(output)\n",
    "        hidden_error=np.dot(output_delta,self.weights_hidden_output.T)\n",
    "        hidden_delta=hidden_error*sigmoid_derivative(self.hidden_output)\n",
    "\n",
    "        self.weights_hidden_output+=np.dot(self.hidden_output.T,output_delta)*learning_rate\n",
    "        self.weights_input_hidden+=np.dot(X.T,hidden_delta)*learning_rate\n",
    "        self.bias_output+=np.sum(output_delta,axis=0,keepdims=True)*learning_rate\n",
    "        self.bias_hidden+=np.sum(hidden_delta,axis=0,keepdims=True)*learning_rate\n",
    "\n",
    "    # train the neural network\n",
    "    def train(self,X,y,epochs,learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            # forward pass\n",
    "            output=self.forward(X)\n",
    "\n",
    "            self.backward(X,y,output,learning_rate)\n",
    "\n",
    "            if epoch % 100==0:\n",
    "                loss=mean_squarred_error(y,output)\n",
    "                print(f'Epoch {epoch}, Loss: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "363621f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## XOR dataset \n",
    "X=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y=np.array([[0],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fe7599a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.27947789780547105\n",
      "Epoch 100, Loss: 0.25216032150526435\n",
      "Epoch 200, Loss: 0.2514871904321104\n",
      "Epoch 300, Loss: 0.2510707986759302\n",
      "Epoch 400, Loss: 0.250796525836693\n",
      "Epoch 500, Loss: 0.2506021874698745\n",
      "Epoch 600, Loss: 0.2504530012680249\n",
      "Epoch 700, Loss: 0.25032893460914646\n",
      "Epoch 800, Loss: 0.2502178834636156\n",
      "Epoch 900, Loss: 0.2501119910503901\n",
      "Epoch 1000, Loss: 0.25000562392896714\n",
      "Epoch 1100, Loss: 0.24989421622344193\n",
      "Epoch 1200, Loss: 0.24977356418538021\n",
      "Epoch 1300, Loss: 0.24963934660945214\n",
      "Epoch 1400, Loss: 0.2494867458153282\n",
      "Epoch 1500, Loss: 0.2493100941657716\n",
      "Epoch 1600, Loss: 0.24910249592737344\n",
      "Epoch 1700, Loss: 0.24885538610924876\n",
      "Epoch 1800, Loss: 0.24855799388967872\n",
      "Epoch 1900, Loss: 0.24819668356699187\n",
      "Epoch 2000, Loss: 0.247754156020581\n",
      "Epoch 2100, Loss: 0.24720851559408696\n",
      "Epoch 2200, Loss: 0.24653225137183132\n",
      "Epoch 2300, Loss: 0.2456912620003518\n",
      "Epoch 2400, Loss: 0.24464418564103513\n",
      "Epoch 2500, Loss: 0.2433424919848537\n",
      "Epoch 2600, Loss: 0.24173203560289436\n",
      "Epoch 2700, Loss: 0.23975697305305688\n",
      "Epoch 2800, Loss: 0.2373668926842136\n",
      "Epoch 2900, Loss: 0.23452733265218997\n",
      "Epoch 3000, Loss: 0.23123225329477926\n",
      "Epoch 3100, Loss: 0.22751475334889038\n",
      "Epoch 3200, Loss: 0.22345077636606112\n",
      "Epoch 3300, Loss: 0.21915177934834384\n",
      "Epoch 3400, Loss: 0.2147469093094023\n",
      "Epoch 3500, Loss: 0.21036057607500022\n",
      "Epoch 3600, Loss: 0.2060933872577197\n",
      "Epoch 3700, Loss: 0.20201177730354866\n",
      "Epoch 3800, Loss: 0.1981468209786673\n",
      "Epoch 3900, Loss: 0.19449920323430006\n",
      "Epoch 4000, Loss: 0.19104652368463013\n",
      "Epoch 4100, Loss: 0.1877501782464034\n",
      "Epoch 4200, Loss: 0.18456053323909077\n",
      "Epoch 4300, Loss: 0.18142009996185693\n",
      "Epoch 4400, Loss: 0.1782646004560851\n",
      "Epoch 4500, Loss: 0.17502082406104738\n",
      "Epoch 4600, Loss: 0.17159669381006976\n",
      "Epoch 4700, Loss: 0.16784855977994798\n",
      "Epoch 4800, Loss: 0.16347803425911211\n",
      "Epoch 4900, Loss: 0.1577022532135804\n",
      "Epoch 5000, Loss: 0.1483130454837831\n",
      "Epoch 5100, Loss: 0.13146448932858784\n",
      "Epoch 5200, Loss: 0.10959695640002533\n",
      "Epoch 5300, Loss: 0.08945429698659517\n",
      "Epoch 5400, Loss: 0.07260734741330979\n",
      "Epoch 5500, Loss: 0.05914709758869659\n",
      "Epoch 5600, Loss: 0.04872434067155207\n",
      "Epoch 5700, Loss: 0.04074176345435279\n",
      "Epoch 5800, Loss: 0.03460442315328403\n",
      "Epoch 5900, Loss: 0.029829846954416275\n",
      "Epoch 6000, Loss: 0.026059103158390412\n",
      "Epoch 6100, Loss: 0.023033839461523493\n",
      "Epoch 6200, Loss: 0.02056947650755369\n",
      "Epoch 6300, Loss: 0.01853347099314328\n",
      "Epoch 6400, Loss: 0.016829589349034585\n",
      "Epoch 6500, Loss: 0.015387002514027937\n",
      "Epoch 6600, Loss: 0.014152821289802275\n",
      "Epoch 6700, Loss: 0.013086982171632004\n",
      "Epoch 6800, Loss: 0.012158716210042341\n",
      "Epoch 6900, Loss: 0.01134408359381188\n",
      "Epoch 7000, Loss: 0.010624230406043864\n",
      "Epoch 7100, Loss: 0.009984139710187594\n",
      "Epoch 7200, Loss: 0.00941172501745678\n",
      "Epoch 7300, Loss: 0.008897163868425453\n",
      "Epoch 7400, Loss: 0.008432401938411589\n",
      "Epoch 7500, Loss: 0.00801077974935835\n",
      "Epoch 7600, Loss: 0.0076267485941423335\n",
      "Epoch 7700, Loss: 0.00727565212085369\n",
      "Epoch 7800, Loss: 0.006953556771133976\n",
      "Epoch 7900, Loss: 0.006657118945157559\n",
      "Epoch 8000, Loss: 0.00638348004719348\n",
      "Epoch 8100, Loss: 0.0061301828925657605\n",
      "Epoch 8200, Loss: 0.005895104624463002\n",
      "Epoch 8300, Loss: 0.005676402496415113\n",
      "Epoch 8400, Loss: 0.005472469758931567\n",
      "Epoch 8500, Loss: 0.005281899540106874\n",
      "Epoch 8600, Loss: 0.005103455094858537\n",
      "Epoch 8700, Loss: 0.004936045161459824\n",
      "Epoch 8800, Loss: 0.004778703439490054\n",
      "Epoch 8900, Loss: 0.004630571413382082\n",
      "Epoch 9000, Loss: 0.004490883907095765\n",
      "Epoch 9100, Loss: 0.0043589568802444\n",
      "Epoch 9200, Loss: 0.0042341770731662755\n",
      "Epoch 9300, Loss: 0.004115993184562725\n",
      "Epoch 9400, Loss: 0.004003908325330558\n",
      "Epoch 9500, Loss: 0.0038974735397868526\n",
      "Epoch 9600, Loss: 0.003796282223403895\n",
      "Epoch 9700, Loss: 0.0036999652965555344\n",
      "Epoch 9800, Loss: 0.00360818701824737\n",
      "Epoch 9900, Loss: 0.00352064134360358\n"
     ]
    }
   ],
   "source": [
    "nn=BasicNeuralNetwork(input_size=2,hidden_size=2,output_size=1)\n",
    "nn.train(X,y,epochs=10000,learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4af24691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test the trained neural network:\n",
      "Input: [0 0],  Predicted Output: [[0.05952613]],actual Output: [0]\n",
      "Input: [0 1],  Predicted Output: [[0.93583078]],actual Output: [1]\n",
      "Input: [1 0],  Predicted Output: [[0.94196877]],actual Output: [1]\n",
      "Input: [1 1],  Predicted Output: [[0.05214903]],actual Output: [0]\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "print(\"\\nTest the trained neural network:\")\n",
    "for i in range(len(X)):\n",
    "    print(f\"Input: {X[i]},  Predicted Output: {nn.forward(X[i])},actual Output: {y[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
